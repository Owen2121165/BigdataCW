# CIFAR-10 Image Classification using Convolutional Neural Networks

## Introduction
This project implements a full machine learning pipeline for image classification using the CIFAR-10 dataset and Convolutional Neural Networks (CNNs). It includes data preparation, exploratory analysis, model development with multiple CNN architectures, model evaluation, and prediction on unseen data. The project compares three CNN architectures and selects the best-performing model based on accuracy and generalisation.

## Business Objectives
The aim is to develop a CNN model that can accurately classify 32x32 color images into one of 10 categories (e.g. ship, airplane, dog). The goal is to achieve a high classification accuracy (>75%) and demonstrate effective training, evaluation, and deployment within a reproducible ML pipeline.

## ML Pipeline

### 1. Data Collection
- Dataset: CIFAR-10, preloaded from `tensorflow.keras.datasets`
- Total: 60,000 images in 10 classes (50,000 training + 10,000 test)
- Preprocessing: Pixel values normalized to [0,1]; data types cast to float32

### 2. Exploratory Data Analysis (EDA)
- Visualized class distribution to check dataset balance
- Sample images plotted to understand the visual characteristics of each class
- Confirmed no missing data or corrupted entries

### 3. Model Building
Three different CNN architectures were constructed:

- **Model 1**: Basic CNN with one convolution layer and a dense layer.
- **Model 2**: Two convolution layers, dropout regularization, and increased depth.
- **Model 3**: Deeper network with batch normalization, dropout, and three convolution layers.

All models used the Adam optimizer and sparse categorical crossentropy loss.

### 4. Model Evaluation
- Each model trained for up to 15 epochs with `EarlyStopping` on validation loss
- Performance metrics included training/validation accuracy and confusion matrix
- Accuracy trends plotted for visual comparison
- **Model 3** outperformed others with highest test accuracy

### 5. Prediction
- Best model (Model 3) evaluated on test dataset
- Confusion matrix visualized class-level performance
- Sample predictions displayed alongside ground-truth labels to assess qualitative results

## Jupyter Notebook Structure
- Imports and setup
- Data loading and validation
- EDA with visualizations
- Model definition (3 architectures)
- Training with early stopping
- Performance comparison
- Prediction and visualization

## Future Work
- Integrate data augmentation to improve generalisation
- Use KerasTuner for automated hyperparameter tuning
- Convert trained model to TensorFlow Lite or ONNX for edge deployment
- Evaluate performance on other datasets (e.g., Tiny ImageNet)

## Libraries and Modules

- `tensorflow` – Used to build and train CNNs.
- `numpy` – Numerical operations on arrays and label handling.
- `matplotlib` – Plots for accuracy trends and image samples.
- `seaborn` – Enhanced visualizations like confusion matrix.
- `sklearn.metrics` – Evaluation metrics such as confusion matrix and classification report.

## Unfixed Bugs
- None at present. All models compiled and trained without error.

## Acknowledgements and References
- ChatGPT was used to assist in generating initial code scaffolding and markdown structure.
- TensorFlow/Keras documentation was consulted to guide model design and training logic.
- CIFAR-10 dataset courtesy of [Krizhevsky & Hinton](https://www.cs.toronto.edu/~kriz/cifar.html).

## Conclusions
A complete image classification pipeline using CNNs was implemented and tested. Among three different architectures, the third (deepest) CNN with regularization provided the best test performance. The project demonstrates strong understanding of model architecture design, training optimisation, and model selection using empirical evidence.
